{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d0086-1ecb-4b6a-907a-661755b8501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 1\n",
    "    \n",
    "Eigenvalues are the special set of scalar values that is associated with the set of linear equations most probably in the matrix equations. The eigenvectors are also termed as characteristic roots. \n",
    "It is a non-zero vector that can be changed at most by its scalar factor after the application of linear transformations.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50219e19-d796-4942-8a70-5da31cd51442",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 2\n",
    "    \n",
    "Eigendecomposition provides us with a tool to decompose a matrix by discovering the eigenvalues and the eigenvectors. \n",
    "This operation can prove useful since it allows certain matrix operations to be easier to perform and it also tells us important facts about the matrix itself.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d117ef-8c98-440d-809d-6fe48efe6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 3\n",
    "    \n",
    "To summarize, an n×n matrix A is diagonalizable if and only if there are enough linearly independent eigenvectors to form a basis of \n",
    "Rn. This occurs precisely when the sum of the dimensions of the distinct eigenspaces = n.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f294aa-5cc3-420e-a9d9-e52808dd544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 4\n",
    "    \n",
    "In the context of eigen-decomposition, the spectral theorem plays a crucial role in understanding the properties of matrices and their diagonalization. The spectral theorem states that for a symmetric matrix, the eigenvectors are orthogonal, and the eigenvalues are real. This theorem is significant in various areas of mathematics, including linear algebra and functional analysis.\n",
    "\n",
    "Now, let's relate the spectral theorem to the diagonalizability of a matrix:\n",
    "\n",
    "1. **Diagonalizability**: A matrix \\( A \\) is said to be diagonalizable if it can be expressed as \\( A = PDP^{-1} \\), where \\( P \\) is a matrix composed of eigenvectors of \\( A \\), and \\( D \\) is a diagonal matrix containing the corresponding eigenvalues of \\( A \\). Diagonalization simplifies matrix operations and makes it easier to analyze and understand the properties of the matrix.\n",
    "\n",
    "2. **Spectral Theorem and Diagonalizability**: The spectral theorem states that for a symmetric matrix, the eigenvectors form an orthogonal basis, and the eigenvalues are real. This theorem is directly related to the diagonalizability of symmetric matrices. Specifically, for a symmetric matrix \\( A \\), the spectral theorem guarantees that it is diagonalizable using an orthogonal matrix of eigenvectors.\n",
    "\n",
    "3. **Example**: Consider the following symmetric matrix:\n",
    "\n",
    "\\[\n",
    "A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 2 \\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "To find the eigenvalues and eigenvectors of \\( A \\), we solve the characteristic equation:\n",
    "\n",
    "\\[\n",
    "\\text{det}(A - \\lambda I) = 0\n",
    "\\]\n",
    "\n",
    "where \\( I \\) is the identity matrix and \\( \\lambda \\) is the eigenvalue.\n",
    "\n",
    "For \\( A \\), the characteristic equation becomes:\n",
    "\n",
    "\\[\n",
    "\\text{det} \\begin{pmatrix} 3 - \\lambda & 1 \\\\ 1 & 2 - \\lambda \\end{pmatrix} = 0\n",
    "\\]\n",
    "\n",
    "Solving this equation yields the eigenvalues \\( \\lambda_1 = 4 \\) and \\( \\lambda_2 = 1 \\).\n",
    "\n",
    "Next, we find the eigenvectors corresponding to each eigenvalue:\n",
    "\n",
    "For \\( \\lambda_1 = 4 \\):\n",
    "\n",
    "\\[\n",
    "A - 4I = \\begin{pmatrix} -1 & 1 \\\\ 1 & -2 \\end{pmatrix} \\rightarrow \\text{eigenvector} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "For \\( \\lambda_2 = 1 \\):\n",
    "\n",
    "\\[\n",
    "A - I = \\begin{pmatrix} 2 & 1 \\\\ 1 & 1 \\end{pmatrix} \\rightarrow \\text{eigenvector} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Since \\( A \\) is symmetric, its eigenvectors are orthogonal.\n",
    "\n",
    "Thus, we have two orthogonal eigenvectors: \\( \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\) and \\( \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} \\), corresponding to eigenvalues 4 and 1, respectively.\n",
    "\n",
    "Now, we can form the matrix \\( P \\) using these eigenvectors and the diagonal matrix \\( D \\) using the eigenvalues:\n",
    "\n",
    "\\[\n",
    "P = \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix} \\quad \\text{and} \\quad D = \\begin{pmatrix} 4 & 0 \\\\ 0 & 1 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "Finally, we verify that \\( A = PDP^{-1} \\). We calculate \\( PDP^{-1} \\) and confirm that it equals \\( A \\).\n",
    "\n",
    "Therefore, the spectral theorem ensures that symmetric matrices like \\( A \\) can be diagonalized using orthogonal matrices of eigenvectors, simplifying their analysis and providing insight into their properties.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef7de8-eaea-4f11-a6de-68fca8cb1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 5\n",
    "    \n",
    "For any square matrix A the eigenvalues are represented by λ and it is calculated by the formula, |A – λI| = 0.\n",
    "After finding the eigenvalue we find the eigenvector by, Av = λv.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695fc47-ab38-4b7c-afb0-9b113928169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 6\n",
    "    \n",
    "Eigenvalues are the special set of scalar values that is associated with the set of linear equations most probably in the matrix equations. \n",
    "The eigenvectors are also termed as characteristic roots. It is a non-zero vector that can be changed at most by its scalar factor after the application of linear transformations.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34270d-a997-4455-86ad-8dd4f88cb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 7\n",
    "    \n",
    "An eigenvector x of a matrix A represents a direction in which the transformation represented by A acts by scaling the vector x\n",
    "by a factor of λ, which is the corresponding eigenvalue.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e8550-519e-4861-a3a6-517e40a95cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 8\n",
    "    \n",
    "Many applications of matrices in both engineering and science utilize eigenvalues and, sometimes, eigenvectors.\n",
    "Control theory, vibration analysis, electric circuits, advanced dynamics and quantum mechanics are just a few of the application areas.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556508cb-5a8c-4ecc-bfe0-842ff8929c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 9\n",
    "    \n",
    "Since a nonzero subspace is infinite, every eigenvalue has infinitely many eigenvectors. (For example, multiplying an eigenvector by a nonzero scalar gives another eigenvector.) \n",
    "On the other hand, there can be at most n linearly independent eigenvectors of an n × n matrix, since R n has dimension n .    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb79eae-16d0-4f83-b6b1-06b14573441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 10\n",
    "    \n",
    "Eigenvalue decomposition finds applications in principal component analysis (PCA), solving differential equations, data compression,\n",
    "image processing, and spectral analysis. \n",
    "It's used in machine learning for feature extraction, dimensionality reduction, and clustering algorithms like k-means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
